{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Cooper | CSC 529 | Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One of the shortcomings of the results in Problem 2 from Assignment#1 is due to the fact of considering a single sample for training set as well as for test set (a single trial of 66% for training and 34% for testing was used to build the model). The objective of this exercise is to repeat the same experiment, but now with different (same size) samples as training and test sets (in other words, repeating the holdout procedure).\n",
    "\n",
    "##### a. Repeat Problem 2.a&b from Assignment#1 on the Wine Recognition Dataset at least 30 times and report the means, variances, and    Confidence Intervals (CI) for the accuracy results on the training and testing sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James Cooper\\Desktop\\DePaul\\Advanced Data Mining\\Homework2\n"
     ]
    }
   ],
   "source": [
    "cd \"C:/Users/James Cooper/Desktop/DePaul/Advanced Data Mining/Homework2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"Wine_data.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonfavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classes  Alcohol  Malic_Acid   Ash  Alcalinity_ash  Magnesium  \\\n",
       "0        1    14.23        1.71  2.43            15.6        127   \n",
       "1        1    13.20        1.78  2.14            11.2        100   \n",
       "2        1    13.16        2.36  2.67            18.6        101   \n",
       "3        1    14.37        1.95  2.50            16.8        113   \n",
       "4        1    13.24        2.59  2.87            21.0        118   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonfavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                 0.28             2.29   \n",
       "1           2.65        2.76                 0.26             1.28   \n",
       "2           2.80        3.24                 0.30             2.81   \n",
       "3           3.85        3.49                 0.24             2.18   \n",
       "4           2.80        2.69                 0.39             1.82   \n",
       "\n",
       "   Color Intensity   Hue  OD280_diluted_wines  Proline  \n",
       "0             5.64  1.04                 3.92     1065  \n",
       "1             4.38  1.05                 3.40     1050  \n",
       "2             5.68  1.03                 3.17     1185  \n",
       "3             7.80  0.86                 3.45     1480  \n",
       "4             4.32  1.04                 2.93      735  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2 = dat.drop('Classes', 1).values\n",
    "classes_2 = dat['Classes'].astype('int').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is just some exploratory analysis for getting an idea of how the data is classified with one decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_2, classes_2, test_size=0.34, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perf_meas(X, y, classifier, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    \n",
    "    y_pred = classifier.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    \n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt = dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.000 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        41\n",
      "          2       1.00      1.00      1.00        48\n",
      "          3       1.00      1.00      1.00        28\n",
      "\n",
      "avg / total       1.00      1.00      1.00       117\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "[[41  0  0]\n",
      " [ 0 48  0]\n",
      " [ 0  0 28]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "perf_meas(X_train, y_train, dt, show_confusion_matrix=True, show_classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.902 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      1.00      0.86        18\n",
      "          2       1.00      1.00      1.00        23\n",
      "          3       1.00      0.70      0.82        20\n",
      "\n",
      "avg / total       0.93      0.90      0.90        61\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "[[18  0  0]\n",
      " [ 0 23  0]\n",
      " [ 6  0 14]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "perf_meas(X_test, y_test, dt, show_confusion_matrix=True, show_classification_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the Decision Tree Classifier is run 30 times to take a look at the scores for each random sample, the sample is taken without replacement. The classifier is run on the training and testing set looping through 30 times. The scores are stored in a list and the mean, variance, and confidence intervals are calculated. We can see that the Decision Tree overfits on the training data with perfect scores, while the test data is highly accurate, but has some variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score_list_train = []\n",
    "for i in range(30):\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_2, classes_2, test_size=0.34, random_state = i)\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    dtree_fit = dtree.fit(X_train, y_train)\n",
    "    y_val_train = y_train\n",
    "    y_hat_train = dtree.predict(X_train)\n",
    "    scores_train = accuracy_score(y_val_train, y_hat_train)\n",
    "    score_list_train.append(scores_train)\n",
    "    print(scores_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean, Variance, and Confidence Intervals of the Decision Tree Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of accuracy scores on the training set: 1.000000\n",
      "The variance on the accuracy of the training set: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print \"The mean value of accuracy scores on the training set: {0:.6f}\".format(np.mean(score_list_train))\n",
    "print \"The variance on the accuracy of the training set: {0:.6f}\".format(np.var(score_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for training set: [1.0000 , 1.0000]\n"
     ]
    }
   ],
   "source": [
    "sorted_results_tr = np.array(score_list_train)\n",
    "sorted_results_tr.sort()\n",
    "lower_confidence = sorted_results_tr[int(0.025 * len(sorted_results_tr))]\n",
    "upper_confidence = sorted_results_tr[int(0.975 * len(sorted_results_tr))]\n",
    "print \"95% confidence interval for training set: [{:0.4f} , {:0.4f}]\".format(lower_confidence, upper_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950819672131\n",
      "0.950819672131\n",
      "0.852459016393\n",
      "0.918032786885\n",
      "0.885245901639\n",
      "0.918032786885\n",
      "0.934426229508\n",
      "0.885245901639\n",
      "0.885245901639\n",
      "0.934426229508\n",
      "0.901639344262\n",
      "0.934426229508\n",
      "0.950819672131\n",
      "0.901639344262\n",
      "0.983606557377\n",
      "0.934426229508\n",
      "0.83606557377\n",
      "0.950819672131\n",
      "0.918032786885\n",
      "0.918032786885\n",
      "0.918032786885\n",
      "0.901639344262\n",
      "0.819672131148\n",
      "0.950819672131\n",
      "0.934426229508\n",
      "0.934426229508\n",
      "0.868852459016\n",
      "0.950819672131\n",
      "0.950819672131\n",
      "0.819672131148\n"
     ]
    }
   ],
   "source": [
    "score_list_test = []\n",
    "for i in range(30):\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_2, classes_2, test_size=0.34, random_state = i)\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    dtree_fit = dtree.fit(X_train, y_train)\n",
    "    y_val = y_test\n",
    "    y_hat = dtree.predict(X_test)\n",
    "    scores = accuracy_score(y_val, y_hat)\n",
    "    score_list_test.append(scores)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Mean, Variance, and Confidence Intervals of the Decision Tree test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of accuracy scores on the test set: 0.916975\n",
      "The variance on the accuracy of the test set: 0.001611\n"
     ]
    }
   ],
   "source": [
    "print \"The mean value of accuracy scores on the test set: {0:.6f}\".format(np.mean(score_list_test))\n",
    "print \"The variance on the accuracy of the test set: {0:.6f}\".format(np.var(score_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for training set: [0.8197 , 0.9836]\n"
     ]
    }
   ],
   "source": [
    "sorted_results_te = np.array(score_list_test)\n",
    "sorted_results_te.sort()\n",
    "\n",
    "lower_confidence = sorted_results_te[int(0.025 * len(sorted_results_te))]\n",
    "upper_confidence = sorted_results_te[int(0.975 * len(sorted_results_te))]\n",
    "print \"95% confidence interval for training set: [{:0.4f} , {:0.4f}]\".format(lower_confidence, upper_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "bclassifier = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98290598290598286, 0.99145299145299148, 1.0, 1.0, 1.0, 1.0, 0.98290598290598286, 0.98290598290598286, 0.99145299145299148, 0.99145299145299148, 0.99145299145299148, 0.99145299145299148, 0.97435897435897434, 0.96581196581196582, 0.97435897435897434, 0.99145299145299148, 0.97435897435897434, 0.98290598290598286, 0.98290598290598286, 0.98290598290598286, 0.97435897435897434, 0.97435897435897434, 0.98290598290598286, 0.98290598290598286, 0.99145299145299148, 0.98290598290598286, 0.99145299145299148, 0.97435897435897434, 0.97435897435897434, 0.98290598290598286]\n"
     ]
    }
   ],
   "source": [
    "scores_bayes_train = []\n",
    "for i in range(30):\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_trainb, X_testb, y_trainb, y_testb = train_test_split(data_2, classes_2, test_size=0.34, random_state = i)\n",
    "    bclassifier = naive_bayes.GaussianNB()\n",
    "    bfitted = bclassifier.fit(X_trainb, y_trainb)\n",
    "    y_valbtr = y_trainb\n",
    "    y_predbtr = bfitted.predict(X_trainb)\n",
    "    scoresbt = accuracy_score(y_valbtr, y_predbtr)\n",
    "    scores_bayes_train.append(scoresbt)\n",
    "print(scores_bayes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Mean, Variance, and Confidence Intervals of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of accuracy scores on the training set: 0.984900\n",
      "The variance on the accuracy of the training set: 0.000081\n"
     ]
    }
   ],
   "source": [
    "print \"The mean value of accuracy scores on the training set: {0:.6f}\".format(np.mean(scores_bayes_train))\n",
    "print \"The variance on the accuracy of the training set: {0:.6f}\".format(np.var(scores_bayes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for training set: [0.9658, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "sorted_resultsbtr = np.array(scores_bayes_train)\n",
    "sorted_resultsbtr.sort()\n",
    "\n",
    "lower_confidencebtr = sorted_resultsbtr[int(0.025 * len(sorted_resultsbtr))]\n",
    "upper_confidencebtr = sorted_resultsbtr[int(0.975 * len(sorted_resultsbtr))]\n",
    "print \"95% confidence interval for training set: [{:0.4f}, {:0.4f}]\".format(lower_confidencebtr, upper_confidencebtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95081967213114749, 0.98360655737704916, 0.96721311475409832, 0.95081967213114749, 0.96721311475409832, 0.91803278688524592, 1.0, 1.0, 0.96721311475409832, 0.95081967213114749, 0.90163934426229508, 0.95081967213114749, 0.95081967213114749, 0.98360655737704916, 1.0, 0.98360655737704916, 0.98360655737704916, 1.0, 0.96721311475409832, 0.96721311475409832, 0.98360655737704916, 0.96721311475409832, 0.96721311475409832, 1.0, 0.96721311475409832, 0.98360655737704916, 0.98360655737704916, 1.0, 0.96721311475409832, 0.96721311475409832]\n"
     ]
    }
   ],
   "source": [
    "scores_bayes_test = []\n",
    "for i in range(30):\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    X_trainb, X_testb, y_trainb, y_testb = train_test_split(data_2, classes_2, test_size=0.34, random_state = i)\n",
    "    bclassifier = naive_bayes.GaussianNB()\n",
    "    bfitted = bclassifier.fit(X_trainb, y_trainb)\n",
    "    y_valb = y_testb\n",
    "    y_predb = bfitted.predict(X_testb)\n",
    "    scoresb = accuracy_score(y_valb, y_predb)\n",
    "    scores_bayes_test.append(scoresb)\n",
    "print(scores_bayes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Mean, Variance, and Confidence Intervals of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of accuracy scores on the test set: 0.971038\n",
      "The variance on the accuracy of the test set: 0.000532\n"
     ]
    }
   ],
   "source": [
    "print \"The mean value of accuracy scores on the test set: {0:.6f}\".format(np.mean(scores_bayes_test))\n",
    "print \"The variance on the accuracy of the test set: {0:.6f}\".format(np.var(scores_bayes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for training set: [0.9016 , 1.0000]\n"
     ]
    }
   ],
   "source": [
    "sorted_resultsbte = np.array(scores_bayes_test)\n",
    "sorted_resultsbte.sort()\n",
    "\n",
    "lower_confidencebte = sorted_resultsbte[int(0.025 * len(sorted_resultsbte))]\n",
    "upper_confidencebte = sorted_resultsbte[int(0.975 * len(sorted_resultsbte))]\n",
    "print \"95% confidence interval for training set: [{:0.4f} , {:0.4f}]\".format(lower_confidencebte, upper_confidencebte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tUsing a pair t-test, compare the mean accuracy of the Naïve Bayes and the mean accuracy of the Decision tree and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_trainb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=9.1752827850597445, pvalue=6.8216106280406834e-13)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind, ttest_ind_from_stats\n",
    "dtr_mean = np.mean(score_list_train)\n",
    "dtr_std = np.std(score_list_train)\n",
    "btr_mean = np.mean(scores_bayes_train)\n",
    "btr_std = np.std(scores_bayes_train)\n",
    "ttest_ind_from_stats(mean1 = dtr_mean, std1 = dtr_std, nobs1 = 30, mean2 = btr_mean, std2 = btr_std, nobs2 = 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=9.1727755346276183, pvalue=5.8937757110133497e-13)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(score_list_train, scores_bayes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function ttest_ind_from_stats, the null hypothesis is that two independent samples have identical average expected values. The function compares the mean and standard deviations of the scores from the decision trees and bayes models that were used with the wine data. We can see that we get a p value low enough to reject the null hypothesis, showing that the models do not have the same average expected values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
